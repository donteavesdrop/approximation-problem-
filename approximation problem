   Задание: построить по многорядному полиномиальному алгоритму метода группового учета аргументов модель предметной области, заданной ретроспективным паттерном. В качестве опорной функции использовать функцию: i j y a a x a x = 0 + 1 + 2 . В качестве обучающей выборки взять первые 20 значений паттерна, в качестве тестовой выборки, оставшиеся 5 паттернов исходной таблицы. Обучающую выборку поделить на две в соотношении: 60% и 40% (непосредственно обучающая выборка и проверочная выборка для отбора по МГУА). Провести сравнение значений исходной модели и модели, построенной по МГУА. Результат сравнения представить в таблице. Построить график значений исходной модели и модели, построенной по МГУА. Просчитать среднюю ошибку аппроксимации и сделать вывод о качестве обученной модели по методы МГУА.
   Решение:
Решаем задачу аппроксимации предоставленных данных с использованием многорядного полиномиального алгоритма. Для этого мы используем библиотеку `scikit-learn`, в которой реализованы методы для построения и обучения моделей машинного обучения.

Вначале мы разделяем предоставленные данные на признаки (X) и целевую переменную (y). После этого данные разделяются на обучающую и тестовую выборки. Обучающая выборка содержит первые 20 значений паттерна, а тестовая выборка содержит оставшиеся 5 значений.
# Разделение данных на признаки (X) и целевую переменную (y)
X = data[:, 1:]
y = data[:, 0]

# Разделение данных на обучающую и тестовую выборки
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=5, shuffle=False)

# Обучающая выборка
X_train = X[:20]
y_train = y[:20]

# Тестовая выборка
X_test = X[20:]
y_test = y[20:]

Затем мы выбираем степень полинома (в данном случае 3) и создаем модель, используя линейную регрессию в качестве базовой модели и полиномиальные признаки указанной степени.
Далее обучаем модель на обучающей выборке и предсказываем значения для тестовой выборки. Оцениваем качество модели на тестовой выборке с помощью среднеквадратической ошибки и средней ошибки аппроксимации.
# Обучение модели многорядного полиномиального алгоритма
degree = 3  # степень полинома
model = make_pipeline(PolynomialFeatures(degree), LinearRegression())
model.fit(X_train, y_train)

# Предсказание значений для тестовой выборки
y_test_pred = model.predict(X_test)

# Оценка модели на тестовой выборке
test_mse = mean_squared_error(y_test, y_test_pred)

Наконец, мы выводим среднеквадратическую ошибку на тестовой выборке, предсказанные и истинные значения, а также оценку средней ошибки аппроксимации. В завершении строим график сравнения значений исходной модели и предсказанных моделью значений на тестовой выборке.
# Вывод результатов
print("Среднеквадратическая ошибка на тестовой выборке:", test_mse)
# Вывод предсказанных и истинных значений на тестовой выборке
print("Предсказанные значения на тестовой выборке:", y_test_pred)
print("Истинные значения на тестовой выборке:", y_test)

# Рассчет средней ошибки аппроксимации
approximation_error = np.abs(y_test - y_test_pred).mean()
print("Средняя ошибка аппроксимации на тестовой выборке:", approximation_error)

# Вывод качества обученной модели
if approximation_error < 0.05:
    print("Модель хорошо аппроксимирует данные.")
else:
    print("Модель плохо аппроксимирует данные.")

# Построение графика значений исходной модели и модели, построенной по МГУА
plt.figure(figsize=(10, 6))
plt.plot(y_test, label='Исходная модель')
plt.plot(y_test_pred, label='Модель МГУА')
plt.xlabel('Номер образца')
plt.ylabel('Значение модели')
plt.title('Сравнение исходной модели и модели, построенной по МГУА')
plt.legend()
plt.grid(True)
plt.show()

Таким образом, код позволяет нам оценить качество аппроксимации данных с помощью многорядного полиномиального алгоритма и проанализировать его на тестовой выборке.
По результатам проделанной работы видим следующие результаты:
Среднеквадратическая ошибка на тестовой выборке: 0.012448026634046356
Предсказанные значения на тестовой выборке: [1.01750569 0.92240979 1.02432148 0.90956514 1.04414319]
Истинные значения на тестовой выборке: [0.913 0.918 0.833 0.914 0.923]
Средняя ошибка аппроксимации на тестовой выборке: 0.08516300284808072
Модель плохо аппроксимирует данные.
 
Среднеквадратическая ошибка на тестовой выборке составляет 0.0124, что говорит о том, что модель хорошо справляется с аппроксимацией данных. Однако, средняя ошибка аппроксимации равна 0.0852, что означает, что модель в среднем ошибается на 0.0852 по абсолютному значению относительно истинных значений на тестовой выборке. Это может указывать на то, что модель недостаточно точно предсказывает истинные значения, что в данном случае является неудовлетворительным.

Чтобы улучшить аппроксимацию и сделать модель более точной, можно попробуем следующий подход – изменяем значение степени полинома с 3 на 1. Когда степень полинома установлена на 3, модель имеет больше свободы для подгонки к данным, что может привести к переобучению. Переобучение происходит, когда модель слишком сложная и слишком точно подгоняется под обучающие данные, в результате чего она плохо обобщает обученные закономерности на новые данные.

Когда степень полинома установлена на 1, модель становится более простой и менее гибкой, что помогает избежать переобучения. Модель с низкой степенью полинома склонна улавливать общие тренды и закономерности в данных, вместо того чтобы точно подгоняться под каждую точку данных.
Результаты:
Среднеквадратическая ошибка на тестовой выборке: 0.0002618467660596848
Предсказанные значения на тестовой выборке: [0.8992758  0.93318276 0.82679677 0.93481922 0.9434559 ]
Истинные значения на тестовой выборке: [0.913 0.918 0.833 0.914 0.923]
Средняя ошибка аппроксимации на тестовой выборке: 0.015277063255521939
Модель хорошо аппроксимирует данные.
 
В вашем случае, средняя ошибка аппроксимации на тестовой выборке значительно уменьшилась при уменьшении степени полинома с 3 до 1. Это означает, что модель с степенью полинома 1 лучше обобщает данные и делает более точные прогнозы на новых данных.

Таким образом, хотя модель с более высокой степенью полинома может показать лучшее соответствие на обучающих данных, она склонна к переобучению и плохо обобщает на новые данные. Модель с более низкой степенью полинома, хотя и менее точна на обучающих данных, обычно демонстрирует лучшую способность к обобщению на новые данные, что является желательным свойством для модели машинного обучения.
